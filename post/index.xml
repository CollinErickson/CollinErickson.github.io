<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Collin Erickson</title>
    <link>/post/</link>
    <description>Recent content in Posts on Collin Erickson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Calculating park factors</title>
      <link>/2019/06/04/calculating-park-factors/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/04/calculating-park-factors/</guid>
      <description>I’ve been thinking a bit about park factors recently.A lot of stats are pretty meaningless without context.40 home runs for a Rockies player is not as good as 40home runs for a Dodgers player because Coors is much morehitter-friendly.Park factors are used to determine how many runs are scored atany given stadium compared to the rest of the league.+/- stats like OPS+ and ERA- adjust for the stadium,making comparisons for players across teams more fair.</description>
    </item>
    
    <item>
      <title>Getting started with RStan</title>
      <link>/2019/06/02/getting-started-with-rstan/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/02/getting-started-with-rstan/</guid>
      <description>I’m trying to learn more about Bayesian modeling,and I want to try to use Bugs/Jags/RStan.RStudio seems to have the most support for RStan(File -&amp;gt; New file has an option for a Stan file,but not the others).So my goal for now is to get a simple example workingusing RStan.
I started by following this blog post:https://www.r-bloggers.com/hierarchical-models-with-rstan-part-1/
Getting errorsHere’s the data in R that needs to be included.</description>
    </item>
    
    <item>
      <title>On what counts do batters swing?</title>
      <link>/2019/06/01/on-what-counts-do-batters-swing/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/01/on-what-counts-do-batters-swing/</guid>
      <description>Recently I’ve heard some things about when batters should swing.Many hitters take the first pitch of an at bat to get a feel for the pitcher.All hitters should take on 3-0.
I want to look at the rate at which batters swing based on the count.
library(magrittr)library(ggplot2)## Registered S3 methods overwritten by &amp;#39;ggplot2&amp;#39;:## method from ## [.quosures rlang## c.quosures rlang## print.quosures rlanglibrary(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionLoad the data as d</description>
    </item>
    
    <item>
      <title>Using launch angle data</title>
      <link>/2019/06/01/using-launch-angle-data/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/06/01/using-launch-angle-data/</guid>
      <description>I’m going to look at some launch angle datausing the data scraped from Baseball Savant.
library(magrittr)library(ggplot2)## Registered S3 methods overwritten by &amp;#39;ggplot2&amp;#39;:## method from ## [.quosures rlang## c.quosures rlang## print.quosures rlanglibrary(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionLoad the data as d</description>
    </item>
    
    <item>
      <title>Nasty pitches</title>
      <link>/2019/05/14/nasty-pitches/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/14/nasty-pitches/</guid>
      <description>library(mlbgameday)library(magrittr)library(ggplot2)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionPitches from PITCHf/x have a feature called nastythat somehow estimates the nastiness of a pitch.https://tht.fangraphs.com/tht-live/gameday-pitchf-x-changes-for-2010/gives a short description of it.
The “nasty” field is presumably a crude attempt to calculate how hard to hit a particular pitch was, on a scale of 0-100.</description>
    </item>
    
    <item>
      <title>Getting better MLB data from BaseballSavant in R</title>
      <link>/2019/05/13/getting-better-mlb-data-from-baseballsavant-in-r/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/13/getting-better-mlb-data-from-baseballsavant-in-r/</guid>
      <description>The MLB data I got using the R package mlbgamedayis kind of disappointing.It doesn’t have things like exit velocity,and I saw last time that it’s very hard to calculateexpected runs.Google recommended the following article:https://billpetti.github.io/2018-02-19-build-statcast-database-rstats/
I looked at it and it seems like it would allow me to get better datathan mlbgameday.It has launch_angle, launch_speed, estimated wOBA, etc.So here I’m going to try to follow the instructions in the postto get a better data set.</description>
    </item>
    
    <item>
      <title>Expected runs for every game state</title>
      <link>/2019/05/11/expected-runs-for-every-game-state/</link>
      <pubDate>Sat, 11 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/11/expected-runs-for-every-game-state/</guid>
      <description>A state in a baseball game is defined by the number outs and which bases have baserunners.We could include the count, inning, etc, but we’re starting with the simplest version.For a given state, there is an expected number of runs a team would score inthe remainder of that inning.These tables are readily available online.I want to try to recreate the tables using data from mlbgameday package.</description>
    </item>
    
    <item>
      <title>BABIP part 2</title>
      <link>/2019/05/09/babip-part-2/</link>
      <pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/09/babip-part-2/</guid>
      <description>Last time I looked into BABIP to see if pitchers could control it.I want to check a couple of more things.
I’m getting the same data as last time.
library(mlbgameday)library(magrittr)library(ggplot2)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, union# Takes hours to get all the data for the yeardat &amp;lt;- get_payload(start = &amp;quot;2018-01-01&amp;quot;, end = &amp;quot;2018-12-31&amp;quot;)Get pitcher names from at bat data.</description>
    </item>
    
    <item>
      <title>BABIP</title>
      <link>/2019/05/07/babip/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/07/babip/</guid>
      <description>Recently I was reading about pitchers having no control over results of a ball in play.This is the main idea behind FIP/DIPS.This goes against the common idea that pitchers can be good if they induce weak contact.I’m going to investigate this in this post.
Similar to last time, I’m using the same data from mlbgameday.
library(mlbgameday)library(magrittr)library(ggplot2)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionGet data.</description>
    </item>
    
    <item>
      <title>Swings and Misses</title>
      <link>/2019/05/06/swings-and-misses/</link>
      <pubDate>Mon, 06 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/06/swings-and-misses/</guid>
      <description>I going to work more with data from mlbgameday.
library(mlbgameday)library(magrittr)library(ggplot2)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionGet data.
# Takes hours to get all the data for the yeardat &amp;lt;- get_payload(start = &amp;quot;2018-01-01&amp;quot;, end = &amp;quot;2018-12-31&amp;quot;)Get pitcher names from at bat data.</description>
    </item>
    
    <item>
      <title>Using mlbgameday to see what pitches get hit</title>
      <link>/2019/04/29/using-mlbgameday-to-see-what-pitches-get-hit/</link>
      <pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/29/using-mlbgameday-to-see-what-pitches-get-hit/</guid>
      <description>Load packages
library(mlbgameday)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionlibrary(ggplot2)library(magrittr)Get data. Using arbitrary dates.
dat &amp;lt;- get_payload(start = &amp;quot;2018-08-01&amp;quot;, end = &amp;quot;2018-08-31&amp;quot;)## Gathering Gameday data, please be patient...## Warning: executing %dopar% sequentially: no parallel backend registeredThis siteis useful for deciphering fields.</description>
    </item>
    
    <item>
      <title>Looking at pitches with the R package mlbgameday</title>
      <link>/2019/03/19/looking-at-pitches-with-the-r-package-mlbgameday/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/19/looking-at-pitches-with-the-r-package-mlbgameday/</guid>
      <description>I’ll be continuing on from the last post.
Load packages first.
library(mlbgameday)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionlibrary(ggplot2)library(magrittr)Get some data.
dat &amp;lt;- get_payload(start = &amp;quot;2018-08-22&amp;quot;, end = &amp;quot;2018-08-22&amp;quot;)## Gathering Gameday data, please be patient...## Warning: executing %dopar% sequentially: no parallel backend registeredWe’re going to be looking at dat$pitch.</description>
    </item>
    
    <item>
      <title>Getting started with R package mlbgameday</title>
      <link>/2019/03/18/getting-started-with-r-package-mlbgameday/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/18/getting-started-with-r-package-mlbgameday/</guid>
      <description>I’m going to start digging into baseball statistics.There are a couple of R packages that facilitate the collecting of datafrom MLB.I’ll be using the R package mlbgameday, mostly because I saw that it wasrecently updated.
Getting some dataFirst we load the package.Along with a couple of other of packages that we’ll need.
library(mlbgameday)library(dplyr)## ## Attaching package: &amp;#39;dplyr&amp;#39;## The following objects are masked from &amp;#39;package:stats&amp;#39;:## ## filter, lag## The following objects are masked from &amp;#39;package:base&amp;#39;:## ## intersect, setdiff, setequal, unionlibrary(ggplot2)library(magrittr)Now we’ll grab some data.</description>
    </item>
    
    <item>
      <title>What is spectral clustering?</title>
      <link>/2018/10/26/what-is-spectral-clustering/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/26/what-is-spectral-clustering/</guid>
      <description>I had never heard of spectral clustering until last week.Then I came acrossthis imagecomparing 9 clustering algorithms on different 2D datasets.
knitr::include_graphics(&amp;quot;https://scikit-learn.org/stable/_images/sphx_glr_plot_cluster_comparison_001.png&amp;quot;)It appeared to me that spectral clustering did the best across all the data,and I realized that the only clustering algorithm I understood was k-means.(DBSCAN might be better based on the results shown, but one step at a time.)So here I’m going to try to figure out what spectral clustering is and how I can implement it.</description>
    </item>
    
    <item>
      <title>Trying the R package ggrough</title>
      <link>/2018/10/20/trying-the-r-package-ggrough/</link>
      <pubDate>Sat, 20 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/20/trying-the-r-package-ggrough/</guid>
      <description>I recently came across the R package ggrough after seeingthis tweetwhile checking the #rstats topic on Twitter.It makes plots that look like they were haphazardly sketched.I figured I’d give it a try to see if I could get it to work.
You can find it on GitHub here.The package is still in progress and has many problems.
Set upFirst you need to install ggrough.</description>
    </item>
    
    <item>
      <title>Creating an autoencoder with TensorFlow in R</title>
      <link>/2018/08/22/creating-an-autoencoder-with-tensorflow-in-r/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/22/creating-an-autoencoder-with-tensorflow-in-r/</guid>
      <description>Once again I’m going to be trying something new,and mainly just using this blog post to track itfor later reference.This time I am going to implement an autoencoder,and I’m going to use the R interface to TensorFlowto do it.
DataI’m not going to use real data.I’m just going to creating a function that will give a sequenceof numbers.These will be fed into the network, with the goal beingto get the same thing out on the other side.</description>
    </item>
    
    <item>
      <title>How to load a pretrained model in TensorFlow</title>
      <link>/2018/08/04/how-to-load-a-pretrained-model-in-tensorflow/</link>
      <pubDate>Sat, 04 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/04/how-to-load-a-pretrained-model-in-tensorflow/</guid>
      <description>At work I struggled for days to load a pretrained model intoTensorFlow before giving up.Then a few weeks later I tried again and it worked fine.I’m going to try to do it again here to make sureI can get it to work.
Why you would use a pretrained modelPretrained models are especially useful for image classification.The convolutional neural networks (CNNs) used for image classificationoften have eight or more layers and over a million parameters.</description>
    </item>
    
    <item>
      <title>Running Python in RStudio with reticulate</title>
      <link>/2018/06/25/running-python-in-rstudio-with-reticulate/</link>
      <pubDate>Mon, 25 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/06/25/running-python-in-rstudio-with-reticulate/</guid>
      <description>One of the main reasons I strongly prefer R to Python is thatRStudio is far better than all Python IDEs I have used.I usually use Spyder for my Python IDE, but it has a lotof shortcomings compared to RStudio.
RStudio has added some Python support, for example in Rmarkdownfiles, in the past.Recently I discovered the R package reticulate which is closelyintegrated with RStudio and lets you run Python code more easilyin RStudio.</description>
    </item>
    
    <item>
      <title>Using crossprod in R</title>
      <link>/2018/04/23/using-crossprod-in-r/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/23/using-crossprod-in-r/</guid>
      <description>Often I have come across the function crossprod in R, and found that it didn’t have much effect. Here I will explore if it is useful and when.
The function crossprod(x,y) is equivalent to t(x) %*% y, i.e., allows you to multiply two matrices or vectors, where the transpose of the first argument is used. There is also the function tcrossprod to transpose the second argument. The function allows you to avoid the operation of finding the transpose, and thus should be faster.</description>
    </item>
    
    <item>
      <title>Don&#39;t invert that matrix in R</title>
      <link>/2018/04/16/don-t-invert-that-matrix-in-r/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/04/16/don-t-invert-that-matrix-in-r/</guid>
      <description>There’s a somewhat famous blog post titled Don’t Invert That Matrix. This topic has also been discussed using R on this blog post. You should read those instead of this. I’m just experimenting to see how important this concept is in R, especially in the cases I use often.
The main ideaOften finding the inverse of a matrix is not the endgoal. If it is, then you have do invert it.</description>
    </item>
    
    <item>
      <title>Using active bindings in R6 classes</title>
      <link>/2018/01/10/using-active-bindings-in-r6-classes/</link>
      <pubDate>Wed, 10 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/10/using-active-bindings-in-r6-classes/</guid>
      <description>I’ve used R6 classes in a lot of my R projects in recent years. They are easier to understand than S3 and S4 objects if you’ve ever done programming with objects in other languages. I also am still not sure how I can have functions act on data in an S3 object. I think it’s not possible, but I’m really not sure. And R6 classes are definitely better than RC objects.</description>
    </item>
    
    <item>
      <title>How I create a new post using Hugo, RStudio, and Git</title>
      <link>/2017/12/11/how-i-create-a-new-post-using-hugo-rstudio-and-git/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/11/how-i-create-a-new-post-using-hugo-rstudio-and-git/</guid>
      <description>I am writing this because I forget myself how to do this. I set up this blog through GitHub following the instructions provided by Robert Myles. Now when I want to make a new post I do the following
1. Opened RStudio to my website-hugo project.2. Create a new postThe posts are created and built using the R package blogdown. To create the new post, I use blogdown::new_post(title=&#39;&amp;lt;insert post name here&amp;gt;&#39;, ext=&#39;.</description>
    </item>
    
    <item>
      <title>Using Snippets in RStudio as Keyboard Shortcuts</title>
      <link>/2017/12/04/using-snippets-in-rstudio-as-keyboard-shortcuts/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/04/using-snippets-in-rstudio-as-keyboard-shortcuts/</guid>
      <description>Code Snippets are a useful feature of RStudio that many people don’t know about. The RStudio Blog post gives good instructions on how they can be used, but I thought I’d share how I use them.
Here are some of the ways I use snippets:
Loading MagrittrOne of my favorite R functions is the pipe operator, %&amp;gt;%, from the Magrittr package. There’s already a keyboard shortcut, Ctrl+Shift+M, for this function.</description>
    </item>
    
    <item>
      <title>How profvis helped give a 2x speedup by changing a single function call (answer: data frames can be really slow)</title>
      <link>/2017/11/24/how-profvis-helped-give-a-2x-speedup-by-changing-a-single-function-call-answer-data-frames-can-be-really-slow/</link>
      <pubDate>Fri, 24 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/11/24/how-profvis-helped-give-a-2x-speedup-by-changing-a-single-function-call-answer-data-frames-can-be-really-slow/</guid>
      <description>Recently I’ve been running computationally intensive simulations that take up to six hours each. This is prohibitively slow, and is assuredly suboptimal since I coded it all, so I decided to do a time profile evaluation to find the bottlenecks in the code. This is easily done in R using the eponymous function from the package profvis.
The following example shows how to use profvis.</description>
    </item>
    
    <item>
      <title>Getting Rcpp to work with my R package</title>
      <link>/2017/08/05/getting-rcpp-to-work-with-my-r-package/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/05/getting-rcpp-to-work-with-my-r-package/</guid>
      <description>I’ve been using Rcpp in my R package GauPro for over a year. I had it working with no errors/warnings/notes in the package check for a long time, but for the last half year I’ve kept getting the same note, shown below.
checking compiled code ... NOTEFile &amp;#39;GauPro/libs/x64/GauPro.dll&amp;#39;:Found no calls to: &amp;#39;R_registerRoutines&amp;#39;, &amp;#39;R_useDynamicSymbols&amp;#39;It is good practice to register native routines and to disable symbolsearch.See &amp;#39;Writing portable packages&amp;#39; in the &amp;#39;Writing R Extensions&amp;#39; manual.</description>
    </item>
    
    <item>
      <title>Running TensorBoard on Windows</title>
      <link>/2017/08/03/running-tensorboard-on-windows/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/03/running-tensorboard-on-windows/</guid>
      <description>## NULLI have TensorFlow on my Windows 7 laptop and want to get Tensorboard to work. I’m hoping I can just follow the basic tutorial and get it to work, but usually some bugs will come up so I’m documenting the process.
To begin I open an Anaconda Prompt and enter activate tensorflow, to activate the environment I created for TensorFlow.
I am following the demo here, so I run the MNIST model file which can be found here.</description>
    </item>
    
    <item>
      <title>Creating a gray box neural network in TensorFlow</title>
      <link>/2017/08/01/creating-a-gray-box-neural-network-in-tensorflow/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/01/creating-a-gray-box-neural-network-in-tensorflow/</guid>
      <description>Generally neural networks act as black boxes. The input goes in, you get output, and there is interpretation of the data that helps you understand the model.
A gray box means that we impose structure on the internal structure of the neural network, so that after the model is fit we can look at the estimated parameters and they will tell us something useful.
One way we can do this is to encode an equation that we want to use near the end of the neural network.</description>
    </item>
    
    <item>
      <title>Getting started with TensorFlow in R</title>
      <link>/2017/08/01/getting-started-with-tensorflow-in-r/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/01/getting-started-with-tensorflow-in-r/</guid>
      <description>I have installed TensorFlow on my Windows laptop, and it appears to work using Python. I’m a heavy R user, so I’d like to be able to run TensorFlow through R (and RStudio).
First I installed the tensorflow library
install.packages(&amp;#39;tensorflow&amp;#39;)library(tensorflow)This warned me that my version of R wasn’t up to date. I updated R to 3.4.1 and RStudio to 1.0.153 to make sure that everything is the current version.</description>
    </item>
    
    <item>
      <title>Getting started with TensorFlow on Windows</title>
      <link>/2017/08/01/getting-started-with-tensorflow-on-windows/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/08/01/getting-started-with-tensorflow-on-windows/</guid>
      <description>I have wanted to try using TensorFlow for a while since it is very popular, and I think it might be able to solve a problem I’m working on this summer. I have a Windows 7 laptop, so I’ll be detailing the installation process for TensorFlow on a Windows computer.
This is mostly for my own reference purposes, you will learn nothing by reading this. I’m just following the details provided by TensorFlow here https://www.</description>
    </item>
    
    <item>
      <title>Setting up a GitHub blog for R users</title>
      <link>/2017/05/26/setting-up-a-github-blog-for-r-users/</link>
      <pubDate>Fri, 26 May 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/05/26/setting-up-a-github-blog-for-r-users/</guid>
      <description>A while back I tried to set up a GitHub blog following instructions using Jekyll and Ruby, which seems to be the recommended method by GitHub. I had lots of trouble following tutorials and getting it to work, and eventually abandoned it.
Recently I tried again, after finding out that I can do it through RStudio, using the R package blogdown. I followed the instructions provided by Robert Myles, and it seems to be working fine so far.</description>
    </item>
    
  </channel>
</rss>